# -*- coding: utf-8 -*-
"""resume.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZB-5N0z3pdLz0DganSJaCZBPecz9nYxB
"""

# Installing all required libraries

"""https://pymupdf.readthedocs.io/en/latest/ -- PyMuPDF documenation

"""

#import the libraries
import fitz
import nltk
import re
from nltk.corpus import stopwords
from google.colab import files

resume_file = files.upload()
resume_pdf = list(resume_file.keys())[0]



# Extracting text from Resume

def extract_text_from_resume(file_path):
  doc = fitz.open(file_path)
  text_in_resume = ""
  for page in doc:
    text_in_resume = text_in_resume + page.get_text()
  return text_in_resume

resume_text = extract_text_from_resume(resume_pdf)



# Pre Process Text
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

from nltk.stem import WordNetLemmatizer

def preprocess_text(text):
  text = re.sub(r'\W+', ' ', text.lower())
  words = text.split()
  lemmatizer = WordNetLemmatizer()
  words_after_stopwords = []
  for w in words:
    if w not in stopwords.words('english'):
      lemma = lemmatizer.lemmatize(w)
      words_after_stopwords.append(lemma)


  return ' '.join(words_after_stopwords)

cleaned_resume = preprocess_text(resume_text)

# Job description

job_description = """Looking for an. AI/ML student with CGPA above 9, who has worked on ambulance routing systems using Python and Streamlit. Should have collaborated with IISc/CDPG and led events like Code Red 25. Experience as IEEE event head and Vice President at Entrepreneurship Cell is required. Skills in NLP, resume classification, TF-IDF vectorization, and cosine similarity are essential.
"""

cleaned_jd = preprocess_text(job_description)



from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def compute_similarity(resume_text, jd):
  cleaned_resume = preprocess_text(resume_text)
  cleaned_jd = preprocess_text(job_description)

  corpus = [cleaned_resume, cleaned_jd]
  vectorizer = TfidfVectorizer(ngram_range=(1,2))
  tfidf_matrix = vectorizer.fit_transform(corpus)
  similarity_scores = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1][0])
  return similarity_scores



compute_similarity(resume_text, job_description)

def missing_keywords(resume_text, jd_text):
  resume_tokens = set( preprocess_text(resume_text).split())
  jd_tokens = set(preprocess_text(jd_text).split())
  missing = jd_tokens - resume_tokens
  return list(missing)[:5]

missing_keywords(resume_text, job_description)

